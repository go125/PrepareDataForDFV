{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL Youtube Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL=[\"https://youtu.be/omA52VIPI20\",\"https://youtu.be/vloCRTmD5YA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!youtube-dl URL[0]\n",
    "#I want to move this in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] omA52VIPI20: Downloading webpage\n",
      "[youtube] omA52VIPI20: Downloading MPD manifest\n",
      "[dashsegments] Total fragments: 9\n",
      "[download] Destination: 20200617Drive3-omA52VIPI20.f137.mp4\n",
      "\u001b[K[download] 100% of 26.77MiB in 00:03.66MiB/s ETA 00:0000\n",
      "[dashsegments] Total fragments: 5\n",
      "[download] Destination: 20200617Drive3-omA52VIPI20.f140.m4a\n",
      "\u001b[K[download] 100% of 617.11KiB in 00:00.45MiB/s ETA 00:000\n",
      "[ffmpeg] Merging formats into \"20200617Drive3-omA52VIPI20.mp4\"\n",
      "Deleting original file 20200617Drive3-omA52VIPI20.f137.mp4 (pass -k to keep)\n",
      "Deleting original file 20200617Drive3-omA52VIPI20.f140.m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "!youtube-dl https://youtu.be/omA52VIPI20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] vloCRTmD5YA: Downloading webpage\n",
      "[youtube] vloCRTmD5YA: Downloading MPD manifest\n",
      "[dashsegments] Total fragments: 26\n",
      "[download] Destination: 20200617Drive2-vloCRTmD5YA.f137.mp4\n",
      "\u001b[K[download] 100% of 82.72MiB in 00:51.37MiB/s ETA 00:001:39\n",
      "[dashsegments] Total fragments: 15\n",
      "[download] Destination: 20200617Drive2-vloCRTmD5YA.f140.m4a\n",
      "\u001b[K[download] 100% of 2.05MiB in 00:122.78KiB/s ETA 00:00\n",
      "[ffmpeg] Merging formats into \"20200617Drive2-vloCRTmD5YA.mp4\"\n",
      "Deleting original file 20200617Drive2-vloCRTmD5YA.f137.mp4 (pass -k to keep)\n",
      "Deleting original file 20200617Drive2-vloCRTmD5YA.f140.m4a (pass -k to keep)\n"
     ]
    }
   ],
   "source": [
    "!youtube-dl https://youtu.be/vloCRTmD5YA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move the downloaded video in other dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I want to write this in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFrames(pathIn, pathOut):\n",
    "    if not os.path.exists(pathOut):\n",
    "        os.mkdir(pathOut)\n",
    "\n",
    "    cap = cv2.VideoCapture(pathIn)\n",
    "    count = 0\n",
    "\n",
    "    while (cap.isOpened()):\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            cv2.imwrite(os.path.join(pathOut, \"frame_{:06d}.jpg\".format(count)), frame)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1():\n",
    "    extractFrames('../IMG_8768.mov', '../all_video/video1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import collections\n",
    "import matplotlib as matplot\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import shutil\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import glob\n",
    "import alignment\n",
    "from alignment import compute_overlap\n",
    "from alignment import align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_path\n",
    "base_path = \"../all_video\"\n",
    "# Root directory of the RCNN project\n",
    "ROOT_DIR = os.path.abspath(\"../Mask_RCNN\")\n",
    "# result WIDTH and HEIGHT\n",
    "WIDTH = 416\n",
    "HEIGHT = 128\n",
    "# calib_cam_to_cam.txt path\n",
    "INPUT_TXT_FILE=\"./calib_cam_to_cam.txt\"\n",
    "# result seq length\n",
    "SEQ_LENGTH = 3\n",
    "# result step size\n",
    "STEPSIZE = 1\n",
    "#result output dir\n",
    "OUTPUT_DIR = '../out'\n",
    "#temp data dir\n",
    "TEMP_DIR=\"../tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0617 12:22:32.056802 140735514981248 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0617 12:22:37.556372 140735514981248 deprecation.py:323] From /anaconda3/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "#delete this line in py file\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs=[f.name for f in os.scandir(base_path) if not f.name.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video2', 'video1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    #This function should be modified if you don't use KITTI dataset!\n",
    "    global number_list,TEMP_DIR\n",
    "    if not TEMP_DIR.endswith('/'):\n",
    "        TEMP_DIR = TEMP_DIR + '/'\n",
    "    number_list=[]\n",
    "    for dataset in data_dirs:\n",
    "        data_year=\"2020\"\n",
    "        data_month=\"06\"\n",
    "        data_date=\"27\"\n",
    "        #Please designate these three variables if you don't use KITTI dataset\n",
    "        IMAGE_DIR=base_path + \"/\"+dataset+ \"/\"\n",
    "        \n",
    "        \n",
    "        file_names=[f.name for f in os.scandir(IMAGE_DIR) if not f.name.startswith('.')]\n",
    "        OUTPUT_DIR1= TEMP_DIR+data_year+\"_\"+data_month+\"_\"+data_date+\"/\"+dataset+'/image_02/data'\n",
    "        \n",
    "        if not os.path.exists(OUTPUT_DIR1+\"/\"):\n",
    "            os.makedirs(OUTPUT_DIR1+\"/\")\n",
    "        make_dataset1(OUTPUT_DIR1,file_names,dataset,IMAGE_DIR)\n",
    "        OUTPUT_DIR2= TEMP_DIR+data_year+\"_\"+data_month+\"_\"+data_date+\"/\"+dataset+'/image_03/data'\n",
    "        \n",
    "        if not os.path.exists(OUTPUT_DIR2+\"/\"):\n",
    "            os.makedirs(OUTPUT_DIR2+\"/\")\n",
    "        make_mask_images(OUTPUT_DIR2,file_names,dataset,IMAGE_DIR)\n",
    "        OUTPUT_TXT_FILE=TEMP_DIR+data_year+\"_\"+data_month+\"_\"+data_date+\"/calib_cam_to_cam.txt\"\n",
    "        \n",
    "        shutil.copyfile(INPUT_TXT_FILE, OUTPUT_TXT_FILE)\n",
    "    \n",
    "    \n",
    "    run_all(file_names)\n",
    "    TXT_RESULT_PATH=OUTPUT_DIR\n",
    "    with open(TXT_RESULT_PATH+\"/train.txt\", mode='w') as f:\n",
    "        f.write('\\n'.join(number_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset1(OUTPUT_DIR1,file_names,dataset,IMAGE_DIR):\n",
    "    for i in range(0,len(file_names)):        \n",
    "        image_file=IMAGE_DIR + file_names[i]\n",
    "        img = cv2.imread(image_file)\n",
    "        \n",
    "        \n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        \n",
    "        if (height/width)>(128/416):\n",
    "            print(\"yes\")\n",
    "            small_height=int(height*(416/width))\n",
    "            print(small_height)\n",
    "            img=cv2.resize(img,(416,small_height))\n",
    "            img = img[(small_height//2-64):(small_height//2+64), 0 : 416] \n",
    "            print(img.shape[:2])\n",
    "        else:\n",
    "            small_width=int(width*(128/height))\n",
    "            img=cv2.resize(img,(small_width,128))\n",
    "            img = img[0:128,(small_width//2-208):(small_width//2+208)] \n",
    "            \n",
    "            \n",
    "            \n",
    "        if not os.path.exists(OUTPUT_DIR1):\n",
    "            os.makedirs(OUTPUT_DIR1)\n",
    "        cv2.imwrite(OUTPUT_DIR1 + '/' + file_names[i] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_images(OUTPUT_DIR2,file_names,dataset,IMAGE_DIR):\n",
    "    for i in range(0,len(file_names)):   \n",
    "        image = skimage.io.imread(os.path.join(IMAGE_DIR, file_names[i]))\n",
    "        \n",
    "        \n",
    "        height, width = image.shape[:2]\n",
    "            \n",
    "        if (height/width)>(128/416):\n",
    "            print(\"yes2\")\n",
    "            small_height=int(height*(416/width))\n",
    "            print(small_height)\n",
    "            image=cv2.resize(image,(416,small_height))\n",
    "            image = image[(small_height//2-64):(small_height//2+64), 0 : 416] \n",
    "            print(image.shape[:2])\n",
    "        else:\n",
    "            small_width=int(width*(128/height))\n",
    "            image=cv2.resize(image,(small_width,128))\n",
    "            image = image[0:128,(small_width//2-208):(small_width//2+208)] \n",
    "            \n",
    "            \n",
    "            \n",
    "        # Run detection\n",
    "        results = model.detect([image], verbose=1)\n",
    "        r = results[0]\n",
    "        # Prepare black image\n",
    "        mask_base = np.zeros((image.shape[0],image.shape[1],image.shape[2]),np.uint8)\n",
    "        after_mask_img = image.copy()\n",
    "        color = (10, 10, 10) #white\n",
    "        number_of_objects=len(r['masks'][0,0])\n",
    "        mask_img=mask_base\n",
    "\n",
    "\n",
    "        for j in range(0,number_of_objects):\n",
    "\n",
    "            mask = r['masks'][:, :, j]\n",
    "\n",
    "            mask_img = visualize.apply_mask(mask_base, mask, color,alpha=1)\n",
    "        \n",
    "            if not os.path.exists(OUTPUT_DIR2):\n",
    "                os.makedirs(OUTPUT_DIR2)\n",
    "        cv2.imwrite(OUTPUT_DIR2 + '/' + file_names[i] + '.jpg',mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(file, start):\n",
    "    file = open(file, 'r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    ret = None\n",
    "    for line in lines:\n",
    "        nline = line.split(': ')\n",
    "        if nline[0]==start:\n",
    "            ret = nline[1].split(' ')\n",
    "            ret = np.array([float(r) for r in ret], dtype=float)\n",
    "            ret = ret.reshape((3,4))[0:3, 0:3]\n",
    "            break\n",
    "    file.close()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, segimg, fx, fy, cx, cy):\n",
    "    # Perform center cropping, preserving 50% vertically.\n",
    "    middle_perc = 0.50\n",
    "    left = 1-middle_perc\n",
    "    half = left/2\n",
    "    a = img[int(img.shape[0]*(half)):int(img.shape[0]*(1-half)), :]\n",
    "    aseg = segimg[int(segimg.shape[0]*(half)):int(segimg.shape[0]*(1-half)), :]\n",
    "    cy /= (1/middle_perc)\n",
    "\n",
    "    # Resize to match target height while preserving aspect ratio.\n",
    "    wdt = int((128*a.shape[1]/a.shape[0]))\n",
    "    x_scaling = float(wdt)/a.shape[1]\n",
    "    y_scaling = 128.0/a.shape[0]\n",
    "    b = cv2.resize(a, (wdt, 128))\n",
    "    bseg = cv2.resize(aseg, (wdt, 128))\n",
    "\n",
    "    # Adjust intrinsics.\n",
    "    fx*=x_scaling\n",
    "    fy*=y_scaling\n",
    "    cx*=x_scaling\n",
    "    cy*=y_scaling\n",
    "\n",
    "    # Perform center cropping horizontally.\n",
    "    remain = b.shape[1] - 416\n",
    "    cx /= (b.shape[1]/416)\n",
    "    c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n",
    "    cseg = bseg[:, int(remain/2):b.shape[1]-int(remain/2)]\n",
    "\n",
    "    return c, cseg, fx, fy, cx, cy\n",
    "\n",
    "#the content of this function doesn't affect the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(file_names):\n",
    "    global number_list,OUTPUT_DIR,TEMP_DIR\n",
    "    ct = 0\n",
    "  \n",
    "  \n",
    "    if not OUTPUT_DIR.endswith('/'):\n",
    "        OUTPUT_DIR = OUTPUT_DIR + '/'\n",
    "    \n",
    "\n",
    "    for d in glob.glob(TEMP_DIR+'*/'):\n",
    "        date = d.split('/')[-2]\n",
    "        file_calibration = d + 'calib_cam_to_cam.txt'\n",
    "        calib_raw = [get_line(file_calibration, 'P_rect_02'), get_line(file_calibration, 'P_rect_03')]\n",
    "\n",
    "        for d2 in glob.glob(d + '*/'):\n",
    "            DIR_NAME = d2.split('/')[-2]\n",
    "            if not os.path.exists(OUTPUT_DIR + DIR_NAME +\"/\"):\n",
    "                os.makedirs(OUTPUT_DIR + DIR_NAME +\"/\")\n",
    "            print('Processing sequence', DIR_NAME)\n",
    "            for subfolder in ['image_02/data']:\n",
    "                ct = 1               \n",
    "                calib_camera = calib_raw[0] if subfolder=='image_02/data' else calib_raw[1]\n",
    "                folder = d2 + subfolder\n",
    "                #files = glob.glob(folder + '/*.png')\n",
    "                files = glob.glob(folder + '/*.jpg')\n",
    "                files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n",
    "                files = sorted(files)\n",
    "                for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n",
    "                    imgnum = str(ct).zfill(10)\n",
    "                    big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n",
    "                    wct = 0\n",
    "\n",
    "                    for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n",
    "                        img = cv2.imread(files[j])\n",
    "                        ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n",
    "\n",
    "                        zoom_x = WIDTH/ORIGINAL_WIDTH\n",
    "                        zoom_y = HEIGHT/ORIGINAL_HEIGHT\n",
    "\n",
    "                        # Adjust intrinsics.\n",
    "                        calib_current = calib_camera.copy()\n",
    "                        calib_current[0, 0] *= zoom_x\n",
    "                        calib_current[0, 2] *= zoom_x\n",
    "                        calib_current[1, 1] *= zoom_y\n",
    "                        calib_current[1, 2] *= zoom_y\n",
    "\n",
    "                        calib_representation = ','.join([str(c) for c in calib_current.flatten()])\n",
    "\n",
    "                        img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "                        big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n",
    "                        wct+=1\n",
    "                    cv2.imwrite(OUTPUT_DIR  + DIR_NAME + '/' +  imgnum + '.png', big_img)\n",
    "                    f = open(OUTPUT_DIR  + DIR_NAME + '/' + imgnum + '_cam.txt', 'w')\n",
    "                    f.write(calib_representation)\n",
    "                    f.close()\n",
    "                    ct+=1\n",
    "                    \n",
    "            for subfolder in ['image_03/data']:\n",
    "                ct = 1\n",
    "                calib_camera = calib_raw[0] if subfolder=='image_02/data' else calib_raw[1]\n",
    "                folder = d2 + subfolder\n",
    "                #files = glob.glob(folder + '/*.png')\n",
    "                files = glob.glob(folder + '/*.jpg')\n",
    "                files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n",
    "                files = sorted(files)\n",
    "                for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n",
    "                    imgnum = str(ct).zfill(10)\n",
    "                    big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n",
    "                    wct = 0\n",
    "\n",
    "                    for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n",
    "                        img = cv2.imread(files[j])\n",
    "                        ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n",
    "\n",
    "                        zoom_x = WIDTH/ORIGINAL_WIDTH\n",
    "                        zoom_y = HEIGHT/ORIGINAL_HEIGHT\n",
    "\n",
    "                        # Adjust intrinsics.\n",
    "                        calib_current = calib_camera.copy()\n",
    "                        calib_current[0, 0] *= zoom_x\n",
    "                        calib_current[0, 2] *= zoom_x\n",
    "                        calib_current[1, 1] *= zoom_y\n",
    "                        calib_current[1, 2] *= zoom_y\n",
    "\n",
    "                        calib_representation = ','.join([str(c) for c in calib_current.flatten()])\n",
    "\n",
    "                        img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "                        big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n",
    "                        wct+=1\n",
    "                    #cv2.imwrite(OUTPUT_DIR + seqname + '/' + imgnum + '.png', big_img)\n",
    "                    #f = open(OUTPUT_DIR + seqname + '/' + imgnum + '_cam.txt', 'w')\n",
    "                    cv2.imwrite(OUTPUT_DIR   +DIR_NAME + '/' + imgnum + '-fseg.png', big_img)\n",
    "                    f = open(OUTPUT_DIR  + DIR_NAME + '/' + imgnum + '_cam.txt', 'w')\n",
    "                    number_list.append(DIR_NAME+\" \"+imgnum)\n",
    "                    f.write(calib_representation)\n",
    "                    f.close()\n",
    "                    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:    0.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:    1.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  150.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes\n",
      "234\n",
      "(128, 416)\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:    9.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  148.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:   12.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  149.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:   13.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  149.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "yes2\n",
      "234\n",
      "(128, 416)\n",
      "Processing 1 images\n",
      "image                    shape: (128, 416, 3)         min:    8.00000  max:  255.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:  149.10000  float64\n",
      "image_metas              shape: (1, 93)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.35390  max:    1.29134  float32\n",
      "Processing sequence video2\n",
      "Processing sequence video1\n"
     ]
    }
   ],
   "source": [
    "make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
