{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import collections\n",
    "import matplotlib as matplot\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import shutil\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import glob\n",
    "import alignment\n",
    "from alignment import compute_overlap\n",
    "from alignment import align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_path\n",
    "base_path = \"/home/ubuntu/data/raw_data/\"\n",
    "# Root directory of the RCNN project\n",
    "ROOT_DIR = os.path.abspath(\"../Mask_RCNN\")\n",
    "# result WIDTH and HEIGHT\n",
    "WIDTH = 416\n",
    "HEIGHT = 192\n",
    "# calib_cam_to_cam.txt path\n",
    "INPUT_TXT_FILE=\"./train_data_example/20200219/calib_cam_to_cam.txt\"\n",
    "# result seq length\n",
    "SEQ_LENGTH = 3\n",
    "# result step size\n",
    "STEPSIZE = 1\n",
    "#result output dir\n",
    "OUTPUT_DIR = '/home/ubuntu/data/kitti_result3'\n",
    "#temp data dir\n",
    "TEMP_DIR=\"/home/ubuntu/data/train_data_example2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "# Import COCO config\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"samples/coco/\"))  # To find local version\n",
    "import coco\n",
    "\n",
    "%matplotlib inline \n",
    "#delete this line in py file\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "class InferenceConfig(coco.CocoConfig):\n",
    "    # Set batch size to 1 since we'll be running inference on\n",
    "    # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Create model object in inference mode.\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
    "\n",
    "# Load weights trained on MS-COCO\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "\n",
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dirs=[\"2011_09_26_drive_0001\",\n",
    "\"2011_09_26_drive_0002\",\n",
    "\"2011_09_26_drive_0005\",\n",
    "\"2011_09_26_drive_0009\",\n",
    "\"2011_09_26_drive_0011\",\n",
    "\"2011_09_26_drive_0013\",\n",
    "\"2011_09_26_drive_0014\",\n",
    "\"2011_09_26_drive_0015\",\n",
    "\"2011_09_26_drive_0017\",\n",
    "\"2011_09_26_drive_0018\",\n",
    "\"2011_09_26_drive_0019\",\n",
    "\"2011_09_26_drive_0020\",\n",
    "\"2011_09_26_drive_0022\",\n",
    "\"2011_09_26_drive_0023\",\n",
    "\"2011_09_26_drive_0027\",\n",
    "\"2011_09_26_drive_0028\",\n",
    "\"2011_09_26_drive_0029\",\n",
    "\"2011_09_26_drive_0032\",\n",
    "\"2011_09_26_drive_0035\",\n",
    "\"2011_09_26_drive_0036\",\n",
    "\"2011_09_26_drive_0039\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    #This function should be modified if you don't use KITTI dataset!\n",
    "    global number_list,TEMP_DIR\n",
    "    number_list=[]\n",
    "    for dataset in data_dirs:\n",
    "        data_year=dataset.split(\"_\")[0]\n",
    "        data_month=dataset.split(\"_\")[1]\n",
    "        data_date=dataset.split(\"_\")[2]\n",
    "        #Please designate these three variables if you don't use KITTI dataset\n",
    "        IMAGE_DIR=base_path+data_year+\"_\"+data_month+\"_\"+data_date+\"/\"+ dataset +\"_sync/image_02/data/\"\n",
    "        #Please change IMAGE_DIR path if you don't use KITTI dataset\n",
    "        \n",
    "        file_names=[f.name for f in os.scandir(IMAGE_DIR) if not f.name.startswith('.')]\n",
    "        OUTPUT_DIR1= TEMP_DIR+data_year+\"_\"+data_month+\"_\"+data_date+\"/\"+dataset+'/image_02/data'\n",
    "        #Please change OUTPUT_DIR1 path if you don't use KITTI dataset\n",
    "        if not os.path.exists(OUTPUT_DIR1+\"/\"):\n",
    "            os.makedirs(OUTPUT_DIR1+\"/\")\n",
    "        make_dataset1(OUTPUT_DIR1,file_names,dataset,IMAGE_DIR)\n",
    "        OUTPUT_DIR2= TEMP_DIR+data_year+\"_\"+data_month+\"_\"+data_date+\"/\"+dataset+'/image_03/data'\n",
    "        #Please change OUTPUT_DIR2 path if you don't use KITTI dataset\n",
    "        if not os.path.exists(OUTPUT_DIR2+\"/\"):\n",
    "            os.makedirs(OUTPUT_DIR2+\"/\")\n",
    "        make_mask_images(OUTPUT_DIR2,file_names,dataset,IMAGE_DIR)\n",
    "        OUTPUT_TXT_FILE=TEMP_DIR+data_year+\"_\"+data_month+\"_\"+data_date+\"/calib_cam_to_cam.txt\"\n",
    "        #Please change OUTPUT_TXT_FILE path if you don't use KITTI dataset\n",
    "        shutil.copyfile(INPUT_TXT_FILE, OUTPUT_TXT_FILE)\n",
    "    \n",
    "    \n",
    "    run_all(file_names)\n",
    "    TXT_RESULT_PATH=OUTPUT_DIR\n",
    "    with open(TXT_RESULT_PATH+\"/train.txt\", mode='w') as f:\n",
    "        f.write('\\n'.join(number_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset1(OUTPUT_DIR1,file_names,dataset,IMAGE_DIR):\n",
    "    for i in range(0,len(file_names)):        \n",
    "        image_file=IMAGE_DIR + file_names[i]\n",
    "        #ここをいじろう\n",
    "        img = cv2.imread(image_file)\n",
    "        img=cv2.resize(img,(WIDTH,HEIGHT))\n",
    "        if not os.path.exists(OUTPUT_DIR1):\n",
    "            os.makedirs(OUTPUT_DIR1)\n",
    "        cv2.imwrite(OUTPUT_DIR1 + '/' + file_names[i] + '.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mask_images(OUTPUT_DIR2,file_names,dataset,IMAGE_DIR):\n",
    "    for i in range(0,len(file_names)):   \n",
    "        image = skimage.io.imread(os.path.join(IMAGE_DIR, file_names[i]))\n",
    "        image=cv2.resize(image,(WIDTH,HEIGHT))\n",
    "        \n",
    "        # Run detection\n",
    "        results = model.detect([image], verbose=1)\n",
    "        r = results[0]\n",
    "        # Prepare black image\n",
    "        mask_base = np.zeros((image.shape[0],image.shape[1],image.shape[2]),np.uint8)\n",
    "        after_mask_img = image.copy()\n",
    "        color = (10, 10, 10) #white\n",
    "        number_of_objects=len(r['masks'][0,0])\n",
    "        mask_img=mask_base\n",
    "\n",
    "\n",
    "        for j in range(0,number_of_objects):\n",
    "\n",
    "            mask = r['masks'][:, :, j]\n",
    "\n",
    "            mask_img = visualize.apply_mask(mask_base, mask, color,alpha=1)\n",
    "        \n",
    "            if not os.path.exists(OUTPUT_DIR2):\n",
    "                os.makedirs(OUTPUT_DIR2)\n",
    "        cv2.imwrite(OUTPUT_DIR2 + '/' + file_names[i] + '.jpg',mask_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(file, start):\n",
    "    file = open(file, 'r')\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "    ret = None\n",
    "    for line in lines:\n",
    "        nline = line.split(': ')\n",
    "        if nline[0]==start:\n",
    "            ret = nline[1].split(' ')\n",
    "            ret = np.array([float(r) for r in ret], dtype=float)\n",
    "            ret = ret.reshape((3,4))[0:3, 0:3]\n",
    "            break\n",
    "    file.close()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, segimg, fx, fy, cx, cy):\n",
    "    # Perform center cropping, preserving 50% vertically.\n",
    "    middle_perc = 0.50\n",
    "    left = 1-middle_perc\n",
    "    half = left/2\n",
    "    a = img[int(img.shape[0]*(half)):int(img.shape[0]*(1-half)), :]\n",
    "    aseg = segimg[int(segimg.shape[0]*(half)):int(segimg.shape[0]*(1-half)), :]\n",
    "    cy /= (1/middle_perc)\n",
    "\n",
    "    # Resize to match target height while preserving aspect ratio.\n",
    "    wdt = int((128*a.shape[1]/a.shape[0]))\n",
    "    x_scaling = float(wdt)/a.shape[1]\n",
    "    y_scaling = 128.0/a.shape[0]\n",
    "    b = cv2.resize(a, (wdt, 128))\n",
    "    bseg = cv2.resize(aseg, (wdt, 128))\n",
    "\n",
    "    # Adjust intrinsics.\n",
    "    fx*=x_scaling\n",
    "    fy*=y_scaling\n",
    "    cx*=x_scaling\n",
    "    cy*=y_scaling\n",
    "\n",
    "    # Perform center cropping horizontally.\n",
    "    remain = b.shape[1] - 416\n",
    "    cx /= (b.shape[1]/416)\n",
    "    c = b[:, int(remain/2):b.shape[1]-int(remain/2)]\n",
    "    cseg = bseg[:, int(remain/2):b.shape[1]-int(remain/2)]\n",
    "\n",
    "    return c, cseg, fx, fy, cx, cy\n",
    "\n",
    "#the content of this function doesn't affect the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(file_names):\n",
    "    global number_list,OUTPUT_DIR,TEMP_DIR\n",
    "    ct = 0\n",
    "  \n",
    "  \n",
    "    if not OUTPUT_DIR.endswith('/'):\n",
    "        OUTPUT_DIR = OUTPUT_DIR + '/'\n",
    "\n",
    "    for d in glob.glob(TEMP_DIR+'*/'):\n",
    "        date = d.split('/')[-2]\n",
    "        file_calibration = d + 'calib_cam_to_cam.txt'\n",
    "        calib_raw = [get_line(file_calibration, 'P_rect_02'), get_line(file_calibration, 'P_rect_03')]\n",
    "\n",
    "        for d2 in glob.glob(d + '*/'):\n",
    "            DIR_NAME = d2.split('/')[-2]\n",
    "            if not os.path.exists(OUTPUT_DIR + DIR_NAME +\"/\"):\n",
    "                os.makedirs(OUTPUT_DIR + DIR_NAME +\"/\")\n",
    "            print('Processing sequence', DIR_NAME)\n",
    "            for subfolder in ['image_02/data']:\n",
    "                ct = 1               \n",
    "                calib_camera = calib_raw[0] if subfolder=='image_02/data' else calib_raw[1]\n",
    "                folder = d2 + subfolder\n",
    "                #files = glob.glob(folder + '/*.png')\n",
    "                files = glob.glob(folder + '/*.jpg')\n",
    "                files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n",
    "                files = sorted(files)\n",
    "                for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n",
    "                    imgnum = str(ct).zfill(10)\n",
    "                    big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n",
    "                    wct = 0\n",
    "\n",
    "                    for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n",
    "                        img = cv2.imread(files[j])\n",
    "                        ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n",
    "\n",
    "                        zoom_x = WIDTH/ORIGINAL_WIDTH\n",
    "                        zoom_y = HEIGHT/ORIGINAL_HEIGHT\n",
    "\n",
    "                        # Adjust intrinsics.\n",
    "                        calib_current = calib_camera.copy()\n",
    "                        calib_current[0, 0] *= zoom_x\n",
    "                        calib_current[0, 2] *= zoom_x\n",
    "                        calib_current[1, 1] *= zoom_y\n",
    "                        calib_current[1, 2] *= zoom_y\n",
    "\n",
    "                        calib_representation = ','.join([str(c) for c in calib_current.flatten()])\n",
    "\n",
    "                        img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "                        big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n",
    "                        wct+=1\n",
    "                    cv2.imwrite(OUTPUT_DIR  + DIR_NAME + '/' +  imgnum + '.png', big_img)\n",
    "                    f = open(OUTPUT_DIR  + DIR_NAME + '/' + imgnum + '_cam.txt', 'w')\n",
    "                    f.write(calib_representation)\n",
    "                    f.close()\n",
    "                    ct+=1\n",
    "                    \n",
    "            for subfolder in ['image_03/data']:\n",
    "                ct = 1\n",
    "                calib_camera = calib_raw[0] if subfolder=='image_02/data' else calib_raw[1]\n",
    "                folder = d2 + subfolder\n",
    "                #files = glob.glob(folder + '/*.png')\n",
    "                files = glob.glob(folder + '/*.jpg')\n",
    "                files = [file for file in files if not 'disp' in file and not 'flip' in file and not 'seg' in file]\n",
    "                files = sorted(files)\n",
    "                for i in range(SEQ_LENGTH, len(files)+1, STEPSIZE):\n",
    "                    imgnum = str(ct).zfill(10)\n",
    "                    big_img = np.zeros(shape=(HEIGHT, WIDTH*SEQ_LENGTH, 3))\n",
    "                    wct = 0\n",
    "\n",
    "                    for j in range(i-SEQ_LENGTH, i):  # Collect frames for this sample.\n",
    "                        img = cv2.imread(files[j])\n",
    "                        ORIGINAL_HEIGHT, ORIGINAL_WIDTH, _ = img.shape\n",
    "\n",
    "                        zoom_x = WIDTH/ORIGINAL_WIDTH\n",
    "                        zoom_y = HEIGHT/ORIGINAL_HEIGHT\n",
    "\n",
    "                        # Adjust intrinsics.\n",
    "                        calib_current = calib_camera.copy()\n",
    "                        calib_current[0, 0] *= zoom_x\n",
    "                        calib_current[0, 2] *= zoom_x\n",
    "                        calib_current[1, 1] *= zoom_y\n",
    "                        calib_current[1, 2] *= zoom_y\n",
    "\n",
    "                        calib_representation = ','.join([str(c) for c in calib_current.flatten()])\n",
    "\n",
    "                        img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "                        big_img[:,wct*WIDTH:(wct+1)*WIDTH] = img\n",
    "                        wct+=1\n",
    "                    #cv2.imwrite(OUTPUT_DIR + seqname + '/' + imgnum + '.png', big_img)\n",
    "                    #f = open(OUTPUT_DIR + seqname + '/' + imgnum + '_cam.txt', 'w')\n",
    "                    cv2.imwrite(OUTPUT_DIR   +DIR_NAME + '/' + imgnum + '-fseg.png', big_img)\n",
    "                    f = open(OUTPUT_DIR  + DIR_NAME + '/' + imgnum + '_cam.txt', 'w')\n",
    "                    number_list.append(DIR_NAME+\" \"+imgnum)\n",
    "                    f.write(calib_representation)\n",
    "                    f.close()\n",
    "                    ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dataset()\n",
    "\n",
    "#Be careful! It takes much time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask RCNN Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "image = skimage.io.imread(os.path.join(IMAGE_DIR, file_names[10]))\n",
    "\n",
    "# Run detection\n",
    "image=cv2.resize(image,(640,640))\n",
    "results = model.detect([image], verbose=1)\n",
    "\n",
    "# Visualize results\n",
    "r = results[0]\n",
    "visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])\n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "print (\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "color_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(figsize=(6, 6))\n",
    "axes.imshow(color_img)\n",
    "axes.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare all black image\n",
    "mask_base = np.zeros((image.shape[0],image.shape[1],image.shape[2]),np.uint8)\n",
    "after_mask_img = image.copy()\n",
    "color = (10, 10, 10) #white\n",
    "\n",
    "#get mask data from the result\n",
    "\n",
    "number_of_objects=len(r['masks'][0,0])\n",
    "\n",
    "mask_img=mask_base\n",
    "for i in range(0,number_of_objects):\n",
    "\n",
    "    mask = r['masks'][:, :, i]\n",
    "\n",
    "    mask_img = visualize.apply_mask(mask_base, mask, color,alpha=1)\n",
    "    #To make the binary image, alpha is set to be 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
